{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 개의 모델 A,B가 있을 때 모델의 성능 비교를 어떻게 할까\\\n",
    "두 모델이 해당 업무의 성능을 누가 더 잘했는지 비교하면 된다\\\n",
    "모델의 성능을 비교하기 위해 모델에게 실제 작업을 시켜보고 정확도를 비교하는 것은 시간이 너무 오래 걸림 -> test data에 대해 빠르게 식으로 계산하는\\\n",
    "모델 내에서 자신의 성능을 수치화하여 결과를 내놓는 PPL(perplexity)를 이용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 언어 모델 평가 방법(Evaluation metric): PPL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 분기 계수(Branching factor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**주의 사항**\\\n",
    "\\\n",
    "\\\n",
    "PPL의 값이 낮다 : 테스트 데이터 상에서 높은 정확도를 보인다 but 사람이 직접 느끼기에 좋은 언어 모델이라는 것을 반드시 의미하는 것은 아님\\\n",
    "\\\n",
    "언어 모델의 PPL(perplexity) -> test data에 의존하므로 두 개 이상의 언어 모델을 비교할 때는 정량적으로 양이 많음, **domain에 알맞는 동일한** test data를 사용해야 신뢰도가 높아짐\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
